{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba89c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b920f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\fabia\\.cache\\kagglehub\\datasets\\meowmeowmeowmeowmeow\\gtsrb-german-traffic-sign\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d5518",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e2e81",
   "metadata": {},
   "source": [
    "## GTSRB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce1b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for GTSRB\n",
    "class GTSRBDataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        \n",
    "        if self.train:\n",
    "            # Training data structure in GTSRB\n",
    "            self.data_dir = os.path.join(root_dir, 'Train')\n",
    "            self.classes = os.listdir(self.data_dir)\n",
    "            self.images = []\n",
    "            self.labels = []\n",
    "            \n",
    "            # Load all images and labels\n",
    "            for class_id in self.classes:\n",
    "                if not os.path.isdir(os.path.join(self.data_dir, class_id)):\n",
    "                    continue\n",
    "                class_dir = os.path.join(self.data_dir, class_id)\n",
    "                for img_file in os.listdir(class_dir):\n",
    "                    if img_file.endswith('.png'):\n",
    "                        self.images.append(os.path.join(class_dir, img_file))\n",
    "                        self.labels.append(int(class_id))\n",
    "        else:\n",
    "            # Test data structure\n",
    "            self.data_dir = root_dir\n",
    "            # Load CSV file with test data information\n",
    "            test_csv = os.path.join(self.data_dir, 'Test.csv')\n",
    "            df = pd.read_csv(test_csv, sep=',')\n",
    "            self.images = [os.path.join(self.data_dir, filename) for filename in df['Path']]\n",
    "            self.labels = df['ClassId'].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a2b7f1",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67569772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "# Create datasets and data loaders\n",
    "def get_data_loaders(root_dir, batch_size=64):\n",
    "    train_dataset = GTSRBDataset(root_dir=root_dir, train=True, transform=train_transforms)\n",
    "    test_dataset = GTSRBDataset(root_dir=root_dir, train=False, transform=test_transforms)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1c434",
   "metadata": {},
   "source": [
    "# Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e19c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignCNN(nn.Module):\n",
    "    def __init__(self, num_classes=43):  # GTSRB has 43 classes\n",
    "        super(TrafficSignCNN, self).__init__()\n",
    "        \n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Fourth convolutional block\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Fully connected layers - assuming input images are 32x32\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        # Block 2\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Block 3\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Block 4\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        \n",
    "        # Fully connected with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b176d2",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1f9a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "Train Loss: 1.7009, Val Loss: 0.6175, Accuracy: 79.33%\n",
      "Epoch 2/20:\n",
      "Train Loss: 0.4455, Val Loss: 0.4225, Accuracy: 86.74%\n",
      "Epoch 3/20:\n",
      "Train Loss: 0.2279, Val Loss: 0.2715, Accuracy: 92.74%\n",
      "Epoch 4/20:\n",
      "Train Loss: 0.1655, Val Loss: 0.2049, Accuracy: 94.05%\n",
      "Epoch 5/20:\n",
      "Train Loss: 0.1337, Val Loss: 0.1628, Accuracy: 95.72%\n",
      "Epoch 6/20:\n",
      "Train Loss: 0.1123, Val Loss: 0.1433, Accuracy: 96.13%\n",
      "Epoch 7/20:\n",
      "Train Loss: 0.1020, Val Loss: 0.1506, Accuracy: 95.63%\n",
      "Epoch 8/20:\n",
      "Train Loss: 0.0905, Val Loss: 0.1634, Accuracy: 95.42%\n",
      "Epoch 9/20:\n",
      "Train Loss: 0.0759, Val Loss: 0.1240, Accuracy: 96.75%\n",
      "Epoch 10/20:\n",
      "Train Loss: 0.0816, Val Loss: 0.1424, Accuracy: 96.25%\n",
      "Epoch 11/20:\n",
      "Train Loss: 0.0729, Val Loss: 0.1557, Accuracy: 95.91%\n",
      "Epoch 12/20:\n",
      "Train Loss: 0.0648, Val Loss: 0.1737, Accuracy: 96.41%\n",
      "Epoch 13/20:\n",
      "Train Loss: 0.0504, Val Loss: 0.1899, Accuracy: 95.55%\n",
      "Epoch 14/20:\n",
      "Train Loss: 0.0323, Val Loss: 0.1024, Accuracy: 97.45%\n",
      "Epoch 15/20:\n",
      "Train Loss: 0.0246, Val Loss: 0.1471, Accuracy: 96.71%\n",
      "Epoch 16/20:\n",
      "Train Loss: 0.0245, Val Loss: 0.1231, Accuracy: 97.24%\n",
      "Epoch 17/20:\n",
      "Train Loss: 0.0264, Val Loss: 0.1452, Accuracy: 96.98%\n",
      "Epoch 18/20:\n",
      "Train Loss: 0.0204, Val Loss: 0.1498, Accuracy: 97.17%\n",
      "Epoch 19/20:\n",
      "Train Loss: 0.0155, Val Loss: 0.1065, Accuracy: 97.56%\n",
      "Epoch 20/20:\n",
      "Train Loss: 0.0116, Val Loss: 0.1187, Accuracy: 97.48%\n",
      "Best Accuracy: 97.56%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, epochs=20, learning_rate=0.001):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(test_loader.dataset)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        # Adjust learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "        # Save best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), 'best_traffic_sign_model.pth')\n",
    "    \n",
    "    print(f'Best Accuracy: {best_accuracy:.2f}%')\n",
    "    return model\n",
    "\n",
    "\n",
    "# Path should be where you unzipped the Kaggle dataset\n",
    "dataset_path = path  # Use the path from kagglehub\n",
    "    \n",
    "# Get data loaders\n",
    "train_loader, test_loader = get_data_loaders(dataset_path)\n",
    "    \n",
    "# Create model\n",
    "model = TrafficSignCNN()\n",
    "    \n",
    "# Train the model\n",
    "trained_model = train_model(model, train_loader, test_loader)\n",
    "    \n",
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load('best_traffic_sign_model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
